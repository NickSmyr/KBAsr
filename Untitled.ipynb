{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d2f58-ae2b-4bd6-bad7-99608dabf0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/home/sm/.cache/huggingface/datasets/common_voice/sv-SE/6.1.0/a1dc74461f6c839bfe1e8cf1262fd4cf24297e3fbd4087a711bd090779023a5e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e91923bcaf4a0eb9640ca13363d317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========commonvoice speech===============\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "81792\n",
      "=========commonvoice speech===============\n"
     ]
    }
   ],
   "source": [
    "import torchaudio.functional as F\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Import model and processor\n",
    "from transformers import Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n",
    "\n",
    "print(\"Init model\")\n",
    "model_name = 'viktor-enzell/wav2vec2-large-voxrex-swedish-4gram'\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)\n",
    "processor = Wav2Vec2ProcessorWithLM.from_pretrained(model_name)\n",
    "\n",
    "# Import and process speech data\n",
    "common_voice = load_dataset('common_voice', 'sv-SE', split='test[:1%]')\n",
    "\n",
    "def speech_file_to_array(sample):\n",
    "    # Convert speech file to array and downsample to 16 kHz\n",
    "    sampling_rate = sample['audio']['sampling_rate']\n",
    "    sample['speech'] = F.resample(torch.tensor(sample['audio']['array']), sampling_rate, 16_000)\n",
    "    return sample\n",
    "\n",
    "common_voice = common_voice.map(speech_file_to_array)\n",
    "\n",
    "# Run inference\n",
    "print(\"=========commonvoice speech===============\")\n",
    "print(type(common_voice['speech']))\n",
    "print(type(common_voice['speech'][0]))\n",
    "print(len(common_voice['speech'][0]))\n",
    "print(\"=========commonvoice speech===============\")\n",
    "inputs = processor(common_voice['speech'], sampling_rate=16_000, return_tensors='pt', padding=True).to(device)\n",
    "\n",
    "#print(\"inf\")\n",
    "with torch.no_grad():\n",
    "    #print(inputs)\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "transcripts = processor.batch_decode(logits.cpu().numpy()).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e8877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
