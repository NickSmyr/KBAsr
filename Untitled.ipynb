{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73adfe4f-7856-4894-afe9-82d693b34c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 11:03:26,295.295 DEBUG __init__:  matplotlib data path: /home/nsmy/miniconda3/envs/speechTech/lib/python3.8/site-packages/matplotlib/mpl-data\n",
      "2022-03-02 11:03:26,298.298 DEBUG __init__:  CONFIGDIR=/home/nsmy/.config/matplotlib\n",
      "2022-03-02 11:03:26,299.299 DEBUG __init__:  interactive is False\n",
      "2022-03-02 11:03:26,299.299 DEBUG __init__:  platform is linux\n",
      "2022-03-02 11:03:26,300.300 DEBUG __init__:  loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_warnings', '_io', 'marshal', 'posix', '_frozen_importlib_external', '_thread', '_weakref', 'time', 'zipimport', '_codecs', 'codecs', 'encodings.aliases', 'encodings', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', '_abc', 'abc', 'io', '_stat', 'stat', '_collections_abc', 'genericpath', 'posixpath', 'os.path', 'os', '_sitebuiltins', '_locale', '_bootlocale', 'types', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib', 'importlib.machinery', 'importlib.abc', '_operator', 'operator', 'keyword', '_heapq', 'heapq', 'itertools', 'reprlib', '_collections', 'collections', '_functools', 'functools', 'contextlib', 'importlib.util', 'google', 'mpl_toolkits', 'pyannote', 'ruamel', 'site', '_weakrefset', 'weakref', 'pkgutil', 'runpy', 'enum', '_sre', 'sre_constants', 'sre_parse', 'sre_compile', 'copyreg', 're', 'ipykernel._version', '_json', 'json.scanner', 'json.decoder', 'json.encoder', 'json', 'errno', 'signal', 'threading', '_posixsubprocess', 'sel\n",
      "2022-03-02 11:03:26,368.368 DEBUG __init__:  CACHEDIR=/home/nsmy/.cache/matplotlib\n",
      "2022-03-02 11:03:26,370.370 DEBUG font_manager:  Using fontManager instance from /home/nsmy/.cache/matplotlib/fontlist-v330.json\n",
      "2022-03-02 11:03:26,640.640 DEBUG pyplot:  Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "2022-03-02 11:03:26,643.643 DEBUG pyplot:  Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from loadfile import *\n",
    "from phonemes import *\n",
    "from preprocess import *\n",
    "from evaluate import *\n",
    "from google_kb_z_speaker.main import *\n",
    "from tqdm.auto import tqdm\n",
    "from experiment_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ecb93-1a0f-4157-b531-a3bcd91bf4f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b076c8c5-bd8e-4b95-af47-781ba8bcb63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker\n",
    "speakers = [\"z21\", \"z20\", \"z28\", \"z29\" ]\n",
    "google_fnames = [ f\"transcriptions/{s}.googleasr\"  for s in speakers]\n",
    "correct_fnames = [f\"transcriptions/{s}.correct\" for s in speakers]\n",
    "kb_fnames = [f\"transcriptions/{s}.kb\" for s in speakers]\n",
    "\n",
    "google_lines = [get_fname_lines(fname) for fname in google_fnames]\n",
    "correct_lines = [get_fname_lines(fname) for fname in correct_fnames]\n",
    "kb_lines = [get_fname_lines(fname) for fname in kb_fnames]\n",
    "\n",
    "[fix_lines(*model) for model in zip(correct_lines, google_lines, kb_lines)]\n",
    "\n",
    "google_lines = reduce(lambda x,y : x + y, google_lines)\n",
    "correct_lines = reduce(lambda x,y : x + y, correct_lines )\n",
    "kb_lines = reduce(lambda x,y : x + y, kb_lines)\n",
    "\n",
    "google_lines = transcriptions(google_lines)\n",
    "correct_lines = transcriptions(correct_lines)\n",
    "kb_lines = transcriptions(kb_lines)\n",
    "\n",
    "google_lines = [preprocess_text(x) for x in google_lines]\n",
    "correct_lines = [preprocess_text(x) for x in correct_lines]\n",
    "kb_lines = [preprocess_text(x) for x in kb_lines]\n",
    "\n",
    "text_data_bunch = [google_lines, correct_lines, kb_lines]\n",
    "phonemizer= init_phonemizer(\"cuda\", \"./models/deep-phonemizer-se.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c0d417-abd3-4d0d-9a37-b418b7e2ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in idxs:\n",
    "#    print(\"=====\")\n",
    "#    print(google_lines[x])\n",
    "#    print(correct_lines[x])\n",
    "#    print(kb_lines[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d7db5b-091b-49dd-977d-3c53302205dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_phonemes(txt : str):\n",
    "    \"\"\"\n",
    "    Creates a list of singular phonemes from the\n",
    "    output of get_swedish_phonemes\n",
    "    \"\"\"\n",
    "    return txt.replace(\"_\", \" \").split()\n",
    "def set_of_all_phonemes(google_lines, correct_lines, kb_lines):\n",
    "    phonemes_set = set()\n",
    "    for g,c,kb in zip(google_lines, correct_lines, kb_lines):\n",
    "        phonemes_set.update(singular_phonemes(g))\n",
    "        phonemes_set.update(singular_phonemes(c))\n",
    "        phonemes_set.update(singular_phonemes(kb))\n",
    "    return phonemes_set\n",
    "def singular_phonemes_preprocess(google_lines, correct_lines, kb_lines):\n",
    "    st = set_of_all_phonemes(google_lines, correct_lines, kb_lines)\n",
    "    mapping = w2id(\" \".join(st))\n",
    "    line2singular_phonemes_str = lambda x : encode_txt(\" \".join(singular_phonemes(x)), mapping)\n",
    "    id2w = {v :k for k,v in mapping.items()}\n",
    "    return [\n",
    "        [line2singular_phonemes_str(x) for x in google_lines],\n",
    "        [line2singular_phonemes_str(x) for x in correct_lines],\n",
    "        [line2singular_phonemes_str(x) for x in kb_lines],\n",
    "        mapping,id2w\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db582a-6aa2-4b3c-8936-7161f8913ca7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Singular phonemes preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0394afa1-8666-4ad9-8eb5-fb020b155ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3724016f29ba49f1856ff52332bf50a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29027881e61e48dfb47dcd96a707cd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a5a68a7eae4b329b976579fa0e1430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "google_lines = [get_swedish_phonemes(x, phonemizer)\n",
    "                for x in tqdm(google_lines)]\n",
    "correct_lines = [get_swedish_phonemes(x, phonemizer)\n",
    "                 for x in tqdm(correct_lines)]\n",
    "kb_lines = [get_swedish_phonemes(x, phonemizer)\n",
    "            for x in tqdm(kb_lines)]\n",
    "\n",
    "st = set_of_all_phonemes(google_lines, correct_lines, kb_lines)\n",
    "# Save phonmes to a file\n",
    "with open(\"all_phonemes\", \"w\") as f:\n",
    "    for ph in st:\n",
    "        f.write(ph + \"\\n\")\n",
    "        \n",
    "google_lines, correct_lines, kb_lines, mapping,id2w = singular_phonemes_preprocess(google_lines, correct_lines, kb_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629ae52-e200-4336-aa42-2e246a351d8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Phoneme-word preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8102f543-80a7-4764-b0fb-a653be1af61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c153e4fa984f0c9eb8629c95d24efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8042b9144e774e468735979f07031322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3630e0e7f902470785ecf278fd97e69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phonemizer = init_phonemizer(\"cuda\", \"./models/deep-phonemizer-se.pt\")\n",
    "\n",
    "google_lines = [preprocess_phonemes(get_swedish_phonemes(x, phonemizer))\n",
    "                for x in tqdm(google_lines)]\n",
    "correct_lines = [preprocess_phonemes(get_swedish_phonemes(x, phonemizer))\n",
    "                 for x in tqdm(correct_lines)]\n",
    "kb_lines = [preprocess_phonemes(get_swedish_phonemes(x, phonemizer))\n",
    "            for x in tqdm(kb_lines)]\n",
    "phoneme_data_bunch = [google_lines, correct_lines, kb_lines] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46fcdedd-eb71-4c56-99c3-44da76922d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "\n",
      "===\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "\n",
      "===\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "\n",
      "===\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "\n",
      "===\n",
      "[]\n",
      "[]\n",
      "[101]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m c \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decode_txt(g, mapping))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decode_txt(c, mapping))\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdecode_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m     idxs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [count]\n\u001b[1;32m     18\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/PycharmProjects/speechTech/preprocess.py:46\u001b[0m, in \u001b[0;36mdecode_txt\u001b[0;34m(txt, mapping)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mDecodes the encoded text created with encode_txt\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m according to the mapping w2i.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m id2w \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([id2w[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m txt])\n",
      "File \u001b[0;32m~/PycharmProjects/speechTech/preprocess.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mDecodes the encoded text created with encode_txt\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m according to the mapping w2i.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m id2w \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mid2w\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m txt])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'e'"
     ]
    }
   ],
   "source": [
    "# Get the lines from the words\n",
    "google_lines, correct_lines, kb_lines = phoneme_data_bunch\n",
    "idxs = []\n",
    "count = 0\n",
    "for g,c,kb in zip(google_lines, correct_lines, kb_lines):\n",
    "    try:\n",
    "        assert c != \"\"\n",
    "    except:\n",
    "        print(\"===\")\n",
    "        print([ord(x) for x in g])\n",
    "        print([ord(x) for x in c])\n",
    "        print([ord(x) for x in kb])\n",
    "        \n",
    "        print(decode_txt(g, mapping))\n",
    "        print(decode_txt(c, mapping))\n",
    "        print(decode_txt(kb, mapping))\n",
    "        idxs += [count]\n",
    "    count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a842aa5e-d16a-45ce-96b5-a385c4626fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_filter = {\n",
    "        \"agreement\" : False,\n",
    "        \"kb_correct\" : False,\n",
    "        \"g_correct\" : False\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fe72b-af55-497e-85cd-596096dd32a3",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda92834-b258-4bcc-b249-aa01f6fd4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phoneme_word_eval(google_lines,correct_lines,kb_lines, _filter):\n",
    "    \n",
    "    google_lines = [preprocess_phonemes(get_swedish_phonemes(x, phonemizer))\n",
    "                for x in tqdm(google_lines)]\n",
    "    correct_lines = [preprocess_phonemes(get_swedish_phonemes(x, phonemizer))\n",
    "                     for x in tqdm(correct_lines)]\n",
    "    kb_lines = [preprocess_phonemes(get_swedish_phonemes(x, phonemizer))\n",
    "                for x in tqdm(kb_lines)]\n",
    "    phoneme_data_bunch = [google_lines, correct_lines, kb_lines] \n",
    "    \n",
    "    #correct_lines, google_lines, kb_lines = filter_lines(correct_lines,google_lines,\n",
    "    #                                                  kb_lines,**_filter)\n",
    "    #correct_lines, google_lines, kb_lines = filter_lines_only_on_agreement(correct_lines, google_lines,\n",
    "    #                                                                       kb_lines, _filter[\"agreement\"])\n",
    "    filter_bunch = [google_lines, correct_lines, kb_lines]\n",
    "    google_wer = wer(correct_lines, google_lines)\n",
    "    kb_wer = wer(correct_lines, kb_lines)\n",
    "\n",
    "    \n",
    "    kei = 0\n",
    "    oei = 0\n",
    "    gei = 0\n",
    "    tei = 0\n",
    "\n",
    "    for c_l, g_l, kb_l in zip(correct_lines, google_lines, kb_lines):\n",
    "        g_s = set(error_idxs(c_l, g_l))\n",
    "        k_s = set(error_idxs(c_l, kb_l))\n",
    "\n",
    "        gei += len(g_s)\n",
    "        kei += len(k_s)\n",
    "        oei += len(g_s & k_s)\n",
    "        tei += len(g_s | k_s)\n",
    "\n",
    "    error_index_overlap = oei / tei\n",
    "   \n",
    "    agreement, g_correct_kb_not, kb_correct_g_not, agreement_not_correct, agreement_correct,\\\n",
    "    both_incorrect_disagreement =\\\n",
    "        percentage_of_agreement(correct_lines, google_lines, kb_lines)\n",
    "    \n",
    "    return {\n",
    "        \"google_wer\" : wer(correct_lines, google_lines),\n",
    "        \"kb_wer\" : wer(correct_lines, kb_lines),\n",
    "        \"agreement\" : agreement,\n",
    "        \"g_correct_kb_not \" : g_correct_kb_not,\n",
    "        \"kb_correct_g_not \" : kb_correct_g_not,\n",
    "        \"agreement_not_correct\" :  agreement_not_correct,\n",
    "        \"both_incorrect_disagreement\" : both_incorrect_disagreement,\n",
    "        \"error_index_overlap\": error_index_overlap\n",
    "    }\n",
    "    \n",
    "def evaluate_lines(google_lines,correct_lines,kb_lines, _filter):\n",
    "    \n",
    "    \n",
    "    #correct_lines, google_lines, kb_lines = filter_lines(correct_lines,google_lines,\n",
    "     #                                                  kb_lines,**_filter)\n",
    "    #correct_lines, google_lines, kb_lines = filter_lines_only_on_agreement(correct_lines, google_lines,\n",
    "    #                                                                       kb_lines, _filter[\"agreement\"])\n",
    "    filter_bunch = [google_lines, correct_lines, kb_lines]\n",
    "\n",
    "    \n",
    "    kei = 0\n",
    "    oei = 0\n",
    "    gei = 0\n",
    "    tei = 0\n",
    "\n",
    "    for c_l, g_l, kb_l in zip(correct_lines, google_lines, kb_lines):\n",
    "        g_s = set(error_idxs(c_l, g_l))\n",
    "        k_s = set(error_idxs(c_l, kb_l))\n",
    "\n",
    "        gei += len(g_s)\n",
    "        kei += len(k_s)\n",
    "        oei += len(g_s & k_s)\n",
    "        tei += len(g_s | k_s)\n",
    "\n",
    "    error_index_overlap = oei / tei\n",
    "   \n",
    "    agreement, g_correct_kb_not, kb_correct_g_not, agreement_not_correct, agreement_correct,\\\n",
    "    both_incorrect_disagreement =\\\n",
    "        percentage_of_agreement(correct_lines, google_lines, kb_lines)\n",
    "\n",
    "    return {\n",
    "        \"google_wer\" : wer(correct_lines, google_lines),\n",
    "        \"kb_wer\" : wer(correct_lines, kb_lines),\n",
    "        \"agreement\" : agreement,\n",
    "        \"g_correct_kb_not \" : g_correct_kb_not,\n",
    "        \"kb_correct_g_not \" : kb_correct_g_not,\n",
    "        \"agreement_not_correct\" :  agreement_not_correct,\n",
    "        \"both_incorrect_disagreement\" : both_incorrect_disagreement,\n",
    "        \"error_index_overlap\": error_index_overlap\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0542fef7-6bf4-440c-898d-7ec329e32aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9922c67e62c46dfaf34e5f6a9be97bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_wer: 0.1983669548511047±0.0\n",
      "kb_wer: 0.19164265129682997±0.0\n",
      "agreement: 0.36553238199780463±0.0\n",
      "g_correct_kb_not : 0.2768166089965398±0.0\n",
      "kb_correct_g_not : 0.15051903114186851±0.0\n",
      "agreement_not_correct: 0.0990990990990991±0.0\n",
      "both_incorrect_disagreement: 0.5726643598615917±0.0\n",
      "error_index_overlap: 0.3029810298102981±0.0\n"
     ]
    }
   ],
   "source": [
    "experiment = evaluate_lines\n",
    "res = experiment_repeats(experiment, 10, google_lines,correct_lines, kb_lines, _filter)\n",
    "print_experiment_report(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b62eb-b0c5-432c-96f0-41ba1b3077e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 43\n",
    "size = 10\n",
    "def get_triad(idx, bunch):\n",
    "    #### Google, correct, Kb\n",
    "    return bunch[0][idx], bunch[1][idx], bunch[2][idx]\n",
    "\n",
    "def plot_triad(triad,ax):\n",
    "    ax.text(0.0, 0.0, triad[0], size=size, rotation=0,\n",
    "             ha=\"center\", va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\",\n",
    "                       ec=(1., 0.5, 0.5),\n",
    "                       fc=(1., 0.8, 0.8),\n",
    "                       )\n",
    "             )\n",
    "\n",
    "    ax.text(0, -2.5,  triad[2], size=size, rotation=0,\n",
    "             ha=\"center\", va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\",\n",
    "                       ec=(153/255, 51/255, 0/255),\n",
    "                       fc=(255/255, 153/255, 102/255),\n",
    "                       )\n",
    "             )\n",
    "    ax.text(0, -5,  triad[1], size=size, rotation=0,\n",
    "             ha=\"center\", va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\",\n",
    "                       ec=(42 / 255, 162 / 255, 42 / 255),\n",
    "                       fc=(133 / 255, 224 / 255, 133 / 255),\n",
    "                       )\n",
    "             )\n",
    "    \n",
    "    ax.set_ylim(-10, 10)\n",
    "    ax.set_xlim(-10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90647867-c260-4671-b7d0-b1bebda24381",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(15, 5))\n",
    "idx = 0\n",
    "plot_triad(get_triad(idx, text_data_bunch) ,axs[0])\n",
    "plot_triad(get_triad(idx, phoneme_data_bunch) ,axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd64d48-f7c6-422f-bc1e-21f8924c3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_triad_correctness(triad):\n",
    "    #### Google, correct, Kb\n",
    "    print(\"Google correct \", triad[1] == triad[0])\n",
    "    print(\"KB correct \", triad[1] == triad[2])\n",
    "    print(\"Agreement \", triad[0] == triad[2])\n",
    "    \n",
    "    print(\"Google WER \", wer(triad[1], triad[0]))\n",
    "    print(\"KB WER \", wer(triad[1], triad[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
