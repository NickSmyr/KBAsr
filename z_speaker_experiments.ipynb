{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73adfe4f-7856-4894-afe9-82d693b34c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 08:54:52,771.771 DEBUG __init__:  matplotlib data path: /home/nsmy/miniconda3/envs/speechTech/lib/python3.8/site-packages/matplotlib/mpl-data\n",
      "2022-03-09 08:54:52,774.774 DEBUG __init__:  CONFIGDIR=/home/nsmy/.config/matplotlib\n",
      "2022-03-09 08:54:52,775.775 DEBUG __init__:  interactive is False\n",
      "2022-03-09 08:54:52,776.776 DEBUG __init__:  platform is linux\n",
      "2022-03-09 08:54:52,776.776 DEBUG __init__:  loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_warnings', '_io', 'marshal', 'posix', '_frozen_importlib_external', '_thread', '_weakref', 'time', 'zipimport', '_codecs', 'codecs', 'encodings.aliases', 'encodings', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', '_abc', 'abc', 'io', '_stat', 'stat', '_collections_abc', 'genericpath', 'posixpath', 'os.path', 'os', '_sitebuiltins', '_locale', '_bootlocale', 'types', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib', 'importlib.machinery', 'importlib.abc', '_operator', 'operator', 'keyword', '_heapq', 'heapq', 'itertools', 'reprlib', '_collections', 'collections', '_functools', 'functools', 'contextlib', 'importlib.util', 'google', 'mpl_toolkits', 'pyannote', 'ruamel', 'site', '_weakrefset', 'weakref', 'pkgutil', 'runpy', 'enum', '_sre', 'sre_constants', 'sre_parse', 'sre_compile', 'copyreg', 're', 'ipykernel._version', '_json', 'json.scanner', 'json.decoder', 'json.encoder', 'json', 'errno', 'signal', 'threading', '_posixsubprocess', 'sel\n",
      "2022-03-09 08:54:52,846.846 DEBUG __init__:  CACHEDIR=/home/nsmy/.cache/matplotlib\n",
      "2022-03-09 08:54:52,848.848 DEBUG font_manager:  Using fontManager instance from /home/nsmy/.cache/matplotlib/fontlist-v330.json\n",
      "2022-03-09 08:54:53,120.120 DEBUG pyplot:  Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "2022-03-09 08:54:53,122.122 DEBUG pyplot:  Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from loadfile import *\n",
    "from phonemes import *\n",
    "from preprocess import *\n",
    "from evaluate import *\n",
    "from google_kb_z_speaker.main import *\n",
    "from tqdm.auto import tqdm\n",
    "from experiment_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ecb93-1a0f-4157-b531-a3bcd91bf4f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b076c8c5-bd8e-4b95-af47-781ba8bcb63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker\n",
    "speakers = [\"z21\", \"z20\", \"z28\", \"z29\"]\n",
    "models = [\"google\", \"correct\", \"kb\"]\n",
    "models2fnameendings = {\n",
    "    \"google\": \"googleasr\",\n",
    "    \"correct\": \"correct\",\n",
    "    \"kb\": \"kb\"\n",
    "}\n",
    "use_new = False\n",
    "\n",
    "# Create filenames model -> List[List[str]] (List[str] are the lines from one filename\n",
    "fnames = {model: [f\"transcriptions{'_new' if use_new else ''}/{sp}.{models2fnameendings[model]}\" for sp in speakers]\n",
    "          for model in models}\n",
    "\n",
    "bunches = {model: [get_fname_lines(fname) for fname in fnames] for model, fnames in fnames.items()}\n",
    "\n",
    "# speakerLines : List[str]\n",
    "# bunch List[speakerLines]\n",
    "# bunches Dict[model, List[speakerLines]]\n",
    "\n",
    "# Create a list [Dict[model,speakerlines] for speaker]\n",
    "\n",
    "list_of_model2speaker_lines = [{model: bunch[i] for model, bunch in bunches.items()} for i in range(len(speakers))]\n",
    "[fix_lines(x) for x in list_of_model2speaker_lines]\n",
    "# recreate bunches Dict[model, List[speakerLines]]\n",
    "bunches = {x: [list_of_model2speaker_lines[i][x] for i in range(len(speakers))] for x in models}\n",
    "# Reduce bunches to bunches_reduced Dict[model, speakerLines_aggr]\n",
    "bunches = {k: reduce(lambda x, y: x + y, v) for k, v in bunches.items()}\n",
    "# Extract the transcriptions\n",
    "bunches = {k: transcriptions(v) for k, v in bunches.items()}\n",
    "# Preprocess  each transcription\n",
    "bunches = {k: [preprocess_text(x) for x in v] for k, v in bunches.items()}\n",
    "\n",
    "# Initialize phonemizer\n",
    "phonemizer = init_phonemizer(\"cuda\", \"./models/deep-phonemizer-se.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85e41e3-6861-4241-a035-ef333c4478ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51bc776-62f6-466d-b238-19ab110372e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_phonemes(txt : str):\n",
    "    \"\"\"\n",
    "    Creates a list of singular phonemes from the\n",
    "    output of get_swedish_phonemes\n",
    "    \"\"\"\n",
    "    return txt.replace(\"_\", \" \").split()\n",
    "\n",
    "def singular_phonemes_preprocess(bunches):\n",
    "    return {k: [\" \".join(singular_phonemes(s)) for s in v] for k,v in bunches.items()}\n",
    "\n",
    "def get_swedish_phonemes_z(bunches, phonemizer,stress_marks=True):\n",
    "    # Phonemizer creates a dict of words2phonemes for each line, so it \n",
    "    # so all phonemes should be created with a single call for consistency\n",
    "    # Impose an order to models\n",
    "    models = list(bunches.keys())\n",
    "    num_lines = len(bunches[\"google\"])\n",
    "    concatenated = reduce(lambda x,y : x+y,[bunches[x] for x in models])\n",
    "    phoneme_lines = get_swedish_phonemes(concatenated, phonemizer, include_stress_marks=stress_marks)\n",
    "    return { model : phoneme_lines[num_lines * i:num_lines * (i+1)] for model,i in zip(models,range(0,len(models)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fe72b-af55-497e-85cd-596096dd32a3",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "19078f25-6972-453a-b873-d173c27fb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(bunches, _filter, phoneme_words, singular_phonemes, preprocess_hook, stress_marks):\n",
    "    if phoneme_words:\n",
    "        bunches = get_swedish_phonemes_z(bunches, phonemizer, stress_marks=stress_marks)\n",
    "        #\n",
    "        bunches = {k : [preprocess_phonemes(x) for x in v] for k,v in bunches.items()}\n",
    "              \n",
    "    if singular_phonemes:\n",
    "        bunches = get_swedish_phonemes_z(bunches, phonemizer, stress_marks=stress_marks)\n",
    "        bunches = singular_phonemes_preprocess(bunches)\n",
    "    \n",
    "\n",
    "    if preprocess_hook is not None:\n",
    "        preprocess_hook(**locals())\n",
    "\n",
    "    if _filter is not None:\n",
    "        if len(_filter) == 1 and \"agreement\" in _filter:\n",
    "            bunches = filter_bunches_only_on_agreement(bunches, _filter[\"agreement\"])\n",
    "        else:\n",
    "            bunches = filter_bunches(bunches,**_filter)\n",
    "        \n",
    "    return {\n",
    "        \"bunches\" : bunches\n",
    "    }\n",
    "\n",
    "def google_kb_wer(bunches):\n",
    "    return {\n",
    "        \"google_wer\" : wer(bunches[\"correct\"], bunches[\"google\"]),\n",
    "        \"kb_wer\" : wer(bunches[\"correct\"], bunches[\"kb\"]),\n",
    "    }\n",
    "def sentence_lengths(bunches):\n",
    "    return {k+\"-avg-length\" : mean([len(x.split(\" \")) for x in v]) for k,v in bunches.items()}\n",
    "\n",
    "def eoi(bunches):\n",
    "    kei = 0\n",
    "    oei = 0\n",
    "    gei = 0\n",
    "    tei = 0\n",
    "\n",
    "    for c_l, g_l, kb_l in zip(bunches[\"correct\"], bunches[\"google\"], bunches[\"kb\"]):\n",
    "        g_s = set(error_idxs(c_l, g_l))\n",
    "        k_s = set(error_idxs(c_l, kb_l))\n",
    "\n",
    "        gei += len(g_s)\n",
    "        kei += len(k_s)\n",
    "        oei += len(g_s & k_s)\n",
    "        tei += len(g_s | k_s)\n",
    "\n",
    "    error_index_overlap = oei / tei\n",
    "    \n",
    "    return {\"error_index_overlap\": error_index_overlap}\n",
    "\n",
    "def lcs_percentage(bunches):\n",
    "    lcses = []\n",
    "    \n",
    "    for c_l, g_l, kb_l in zip(bunches[\"correct\"], bunches[\"google\"], bunches[\"kb\"]):\n",
    "        total_length_before = len(g_l.split(\" \")) + len(kb_l.split(\" \"))\n",
    "        words_set = set(g_l.split(\" \") + kb_l.split(\" \"))\n",
    "        w2char = { x : chr(i) for i,x in enumerate(words_set)}\n",
    "        g_l_enc = \"\".join([w2char[w] for w in g_l.split(\" \")])\n",
    "        kb_l_enc = \"\".join([w2char[w] for w in kb_l.split(\" \")])\n",
    "        assert total_length_before == (len(g_l_enc) + len(kb_l_enc))\n",
    "        \n",
    "        s = SequenceMatcher(None, g_l_enc, kb_l_enc)\n",
    "        lcs = ''.join([g_l_enc[block.a:(block.a + block.size)] for block in s.get_matching_blocks()])\n",
    "        lcses.append(len(lcs)/ len(c_l.split(\" \")))\n",
    "    \n",
    "    return {\"lcs-mean\": mean(lcses)}\n",
    "          \n",
    "def agreement_percentages(bunches): \n",
    "   \n",
    "    agreement, g_correct_kb_not, kb_correct_g_not, agreement_not_correct, agreement_correct,\\\n",
    "    both_incorrect_disagreement =\\\n",
    "        percentage_of_agreement(bunches)\n",
    "    \n",
    "    return {  \n",
    "        \"agreement\" : agreement,\n",
    "        \"g_correct_kb_not \" : g_correct_kb_not,\n",
    "        \"kb_correct_g_not \" : kb_correct_g_not,\n",
    "        \"agreement_not_correct\" :  agreement_not_correct,\n",
    "        \"both_incorrect_disagreement\" : both_incorrect_disagreement,\n",
    "    }\n",
    "\n",
    "def meval(bunches, _filter=None, phoneme_words=None, singular_phonemes=None, preprocess_hook=None, stress_marks=None):\n",
    "    bunches = preprocess(bunches, _filter, phoneme_words, singular_phonemes, preprocess_hook, stress_marks)[\"bunches\"]\n",
    "    res =  {**google_kb_wer(bunches), **sentence_lengths(bunches), **lcs_percentage(bunches)}\n",
    "    if _filter is None:\n",
    "        return {**evaluate_lines(bunches), **res, **eoi(bunches)}\n",
    "    else:\n",
    "        return {**res}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ad7b6b41-8010-49fc-8c7b-38f364dcbb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "a = Dict[str,List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "80459f9d-0927-4f02-a481-2cb16a6ed584",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = List[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "44703536-62e8-4a08-b378-c3bc4ece4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "def locate_empty_lines(**kwargs):\n",
    "    print(kwargs[\"google_lines\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0542fef7-6bf4-440c-898d-7ec329e32aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bf61425b204921868366135080ee02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_wer: 0.24423976608187134±0.00045767473223679223\n",
      "kb_wer: 0.0±0.0\n",
      "correct-avg-length: 7.975±0.013975424859373685\n",
      "google-avg-length: 7.419649122807018±0.006668974669736086\n",
      "kb-avg-length: 7.975±0.013975424859373685\n",
      "lcs-mean: 0.7063615546400865±0.00043987800237852223\n"
     ]
    }
   ],
   "source": [
    "experiment = meval\n",
    "_filter = {\n",
    "    \"agreement\" : False,\n",
    "    \"g_correct\" : False,\n",
    "    \"kb_correct\" : True,\n",
    "}\n",
    "kwargs = {\n",
    "    \"_filter\": _filter, \n",
    "    \"phoneme_words\" : True,\n",
    "    \"singular_phonemes\" : False,\n",
    "    \"preprocess_hook\" : None,\n",
    "    \"stress_marks\" : False\n",
    "}\n",
    "res = experiment_repeats(experiment, 5, bunches, **kwargs)\n",
    "print_experiment_report(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2e6ab3ba-6d70-45b4-b103-96fd98bb3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "str_a = \"asdasf\"\n",
    "str_b = \"aaasBCDaeFGhsdgadijKaadMn\"\n",
    "s = SequenceMatcher(None, str_a, str_b)\n",
    "\n",
    "lcs = ''.join([str_a[block.a:(block.a + block.size)] for block in s.get_matching_blocks()])\n",
    "# lcs = 'BCDFGKLM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c441229e-6671-46f0-a2e3-d0ba0db5be00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdasf'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9674509f-37ad-47d0-963b-0ffb230fbc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match(a=0, b=2, size=2),\n",
       " Match(a=2, b=13, size=1),\n",
       " Match(a=3, b=15, size=1),\n",
       " Match(a=6, b=25, size=0)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.get_matching_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "365b66a4-891a-459c-91c4-555413a254a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'google_lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgoogle_lines\u001b[49m\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m30\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'google_lines' is not defined"
     ]
    }
   ],
   "source": [
    "google_lines.index(\"30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e0c3e5-312d-4bae-80f1-75f07c342a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(phonemizer([\"jag\" for x in range(10000)], \"se\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227d897-599e-40a2-8365-d8aadef188c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(get_swedish_phonemes([\"ja\" for x in range(10000)], phonemizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731e9a5-809f-426a-a311-66203ab85f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for x in tqdm(range(1000)):\n",
    "    torch.manual_seed(0)\n",
    "    s.append(phonemizer('30', \"se\"))\n",
    "set(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc1c5d-5c48-442b-9a09-0e2f8778863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for x in tqdm(range(15)):\n",
    "    #torch.manual_seed(0)\n",
    "    s.append(get_swedish_phonemes('ja', phonemizer))\n",
    "set(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cc4b62eb-b0c5-432c-96f0-41ba1b3077e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3878495266.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [154]\u001b[0;36m\u001b[0m\n\u001b[0;31m    size = 10a\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "idx = 43\n",
    "size = 10\n",
    "def get_triad(idx, bunch):\n",
    "    #### Google, correct, Kb\n",
    "    return bunch[0][idx], bunch[1][idx], bunch[2][idx]\n",
    "\n",
    "def plot_triad(triad,ax):\n",
    "    ax.text(0.0, 0.0, triad[0], size=size, rotation=0,\n",
    "             ha=\"center\", va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\",\n",
    "                       ec=(1., 0.5, 0.5),\n",
    "                       fc=(1., 0.8, 0.8),\n",
    "                       )\n",
    "             )\n",
    "\n",
    "    ax.text(0, -2.5,  triad[2], size=size, rotation=0,\n",
    "             ha=\"center\", va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\",\n",
    "                       ec=(153/255, 51/255, 0/255),\n",
    "                       fc=(255/255, 153/255, 102/255),\n",
    "                       )\n",
    "             )\n",
    "    ax.text(0, -5,  triad[1], size=size, rotation=0,\n",
    "             ha=\"center\", va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\",\n",
    "                       ec=(42 / 255, 162 / 255, 42 / 255),\n",
    "                       fc=(133 / 255, 224 / 255, 133 / 255),\n",
    "                       )\n",
    "             )\n",
    "    \n",
    "    ax.set_ylim(-10, 10)\n",
    "    ax.set_xlim(-10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90647867-c260-4671-b7d0-b1bebda24381",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(15, 5))\n",
    "idx = 0\n",
    "plot_triad(get_triad(idx, text_data_bunch) ,axs[0])\n",
    "plot_triad(get_triad(idx, phoneme_data_bunch) ,axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd64d48-f7c6-422f-bc1e-21f8924c3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_triad_correctness(triad):\n",
    "    #### Google, correct, Kb\n",
    "    print(\"Google correct \", triad[1] == triad[0])\n",
    "    print(\"KB correct \", triad[1] == triad[2])\n",
    "    print(\"Agreement \", triad[0] == triad[2])\n",
    "    \n",
    "    print(\"Google WER \", wer(triad[1], triad[0]))\n",
    "    print(\"KB WER \", wer(triad[1], triad[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89ef48-0a06-4246-9fb9-52f39087f993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
